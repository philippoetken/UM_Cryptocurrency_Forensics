{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from py2neo import Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXECUTE: WalletClustering_neo4jConnect notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./WalletClustering_neo4jConnect.ipynb # includes Neo4J connector\n",
    "# methods & variables of notebook can be referenced\n",
    "\n",
    "#session = Graph(\"neo4j://127.0.0.1:7687\", auth=(\"team\", \"F0110wTh€M0n€y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response\n",
    "\n",
    "conn = Neo4jConnection(uri=\"neo4j://127.0.0.1:7687\", user=\"team\", pwd=\"F0110wTh€M0n€y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster wallets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mihTemplate = '''\n",
    "MATCH (:Address{address:\"%s\"})-[:SENDS]->(t:Transaction),\n",
    "(walletMember:Address)-[:SENDS]->(t:Transaction)\n",
    "RETURN DISTINCT walletMember\n",
    "'''\n",
    "#address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12sDU3FyYJXc2oRzE6XXuuhVHCBJvaoCC8', '1348ThkNoDupq1bws95diMiL8haGs61K7M', '13iQsrwBYdrLpnitG5EV79o3PeHjH8XUBc', '13Pcmh4dKJE8Aqrhq4ZZwmM1sbKFcMQEEV', '15K9Zj1AU2hjT3ebZMtWqDsMv3fFxTNwpf', '15soXrE3NJBMkkQhrccXonTT9bpjpPvE67', '164fawNZVwsR5SamAJypvCMtkMx4Xv1B3f', '179bzhS4FY7qLDza9YjuorhWyXVVYZu2YH', '17QAWGVpFV4gZ25NQug46e5mBho4uDP6MD', '17UUXDzPGkMwWrabhtk7YCha88tSoua2Vr', '19D1iGzDr7FyAdiy3ZZdxMd6ttHj1kj6WW', '19XVEDZCGVMA9WCF1qUayxtnjUnyD7zDDQ', '1A7pDH1EdrkH9YZtsPnc8uzirBFnAN9Eay', '1BPf9qr7M5xUgNHUYtrQtEKvUKcyERzXao', '1C6hetVWVXZnS6P2BYBNu5Y1ZJ57JyXGac', '1DrhHEkv42JVwiDQNi28JFdSuiSGgPNXwP', '1EDcKCRypUTFoTZbxDWF9MBAT4W7XUGB32', '1EfmRn6Bp3cjrTBubaH8MzRRc2ikSjNGXw', '1EnX6BuJiGWydqXJT9BN5dSvfLg3QW4Mdz', '1EVTZmTMqZPMzGxsug9TXBtvPJZH8dXSCK', '1EYya5dfNvuYDwpeboGKBtkXzJcEHMCQXR', '1GALPyvUDDXqA6H2eHQ9Y1yidfQ6T1Drvn', '1GC2SjzCyCwxo1uxTi28oqn9L3mJj7bLPs', '1Gg25VzQkqCizXHNSNet4RoysLEe19su4s', '1JpSBaUwrZaEgmsYka7mzm9t3Z4syyaw7A', '1LhRW1msre1cFgT7fBY2BRrZ4ANMPwVj9u', '1Lm9BCDUKoBUk888DCXewM5p8bJyr83cEp', '1LPTaRfyoNwvwAtmYzcetZLjBfUxVkJrr4', '1MMaU5nTrFdPZotfwdbv1wWnFjLCTFbpPY', '1QH9hfeSSb2iftcVpgpQp3NsFD174crFoW', '1uLdz4wXrcXjCy2CqLWuJUiE85Y7SJ1ge', '1ULEqcd5te8AWqFpH7HD4KvJZ1AKcJPam', '31yqH1jVEPDJ7x9L648Ec5umM2G3zNDoe5', '3422VtS7UtCvXYxoXMVp6eZupR252z85oC', '3FWSkG5NmyXF3rqMav7piXiJUDYzKpgFRT', '3HQJ9ta7TmYNRjkbY3nbMGdHzNCCiXs3Ui', '3MhdvQccMd5zAh92WrW7SpcHXwfW1uiamD', '3PajPWymUexhewHPczmLQ8CMYatKAGNj3y', 'bc1qg9h7s7hn4t9m7uw26gnwfm7xfxk77fkj878sg3']\n"
     ]
    }
   ],
   "source": [
    "# use existing terrorAddressList if exists\n",
    "if not os.path.exists('output\\\\terrorAddressList.pickle'):\n",
    "    createTerrorAddressList()\n",
    "\n",
    "terrorAddressList = pickle.load(open('output\\\\terrorAddressList.pickle', 'rb'))\n",
    "print(terrorAddressList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mihWhere = \"\"\"MATCH (a:Address)-[:SENDS]->(t:Transaction), (walletMember:Address)-[:SENDS]->(t:Transaction) \n",
    "where a.address in [\\\"{0}\\\",\\\"{1}\\\",\\\"{2}\\\",\\\"{3}\\\",\\\"{4}\\\",\\\"{5}\\\",\\\"{6}\\\",\\\"{7}\\\",\\\"{8}\\\",\\\"{9}\\\"]\n",
    "RETURN DISTINCT walletMember\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWalletAddresses(address, walletName):\n",
    "  \n",
    "  query = \"\"\"CALL apoc.periodic.iterate( 'MATCH (a:Address {address: \"%s\"})-[:SENDS]->(t:Transaction), (walletMember:Address)-[:SENDS]->(t:Transaction) RETURN  walletMember',\n",
    "  'set walletMember.association = \"%s\"', {batchSize:1000, parallel:true})\"\"\" % (address, walletName)\n",
    "  return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_association = \"\"\"Match (a:Address {address: '%s'}) \n",
    "where a.association is not null\n",
    "return true\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through the addresses and finding all the addresses that are connected to the input address.\n",
    "# Store all responses in a dictionary and instead of looping over every item and adding only new Addresses to the list,\n",
    "# write all records of a response into the dictionary. They addresses are the keys\n",
    "# additionally use a batched version if the amount of retrieved records is greater than 10\n",
    "def iterMultiInputClustering_old(address):\n",
    "\n",
    "    # create initial set of addresses\n",
    "    walletAddresses = {address: 1}\n",
    "    response = conn.query(mihTemplate % address, db='neo4j')\n",
    "\n",
    "    # store every found address as key in the dictionary, values do not matter here, so we just pass 1\n",
    "    for record in response:\n",
    "       walletAddresses [record[0]._properties[\"address\"]]= 1 \n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    while i < len(walletAddresses):\n",
    "\n",
    "        # generate a list of the keys to get an index; this is necessary for the batching\n",
    "        list_ofKeys = list(walletAddresses.keys())\n",
    "        \n",
    "        # if there are less than 10 addresses left between i and the maximum; then no batching is possible\n",
    "        if len(walletAddresses) - i <= 10 :\n",
    "\n",
    "            response = conn.query(mihTemplate % list_ofKeys[i], db='neo4j')\n",
    "            \n",
    "            # this automatically resolves duplicates. Instead of iterating over every address one by one in the list and comparing them with the existing set, \n",
    "            # this is more faster since the dictionaries are actually hash tables. So it reaches less than logarithmic runtime\n",
    "            for record in response:\n",
    "                walletAddresses [record[0]._properties[\"address\"]]= 1 \n",
    "            i += 1\n",
    "            list_ofKeys = list(walletAddresses.keys())\n",
    "        \n",
    "        \n",
    "       # batching 10 addresses at once to avoid querying every single transaction in the dictionary\n",
    "       # only possible if there are more than 10 addresses left in the dictionary\n",
    "       # question is if we can further improve this... like with 500 and a function in between that creates a string\n",
    "        while 10 < len(walletAddresses) - i:\n",
    "\n",
    "            response = conn.query(mihWhere.format(list_ofKeys[i], list_ofKeys[i+1], list_ofKeys[i+2], list_ofKeys[i+3], list_ofKeys[i+4], list_ofKeys[i+5]\n",
    "            , list_ofKeys[i+6], list_ofKeys[i+7], list_ofKeys[i+8], list_ofKeys[i+9] ), db='neo4j')\n",
    "\n",
    "            #same as above\n",
    "            for record in response:\n",
    "                walletAddresses [record[0]._properties[\"address\"]]= 1\n",
    "            i += 10\n",
    "            list_ofKeys = list(walletAddresses.keys())\n",
    "    \n",
    "    source = string.ascii_letters + string.digits\n",
    "    walletString = ''.join((random.choice(source) for i in range(32)))\n",
    "    \n",
    "    print(\"Updating ... \"+ str(address) +\", with size \" + str(len(walletAddresses)) + \": \" + walletString)\n",
    "    list_of_Addresses = str(list(walletAddresses))\n",
    "    \n",
    "    query = \"\"\"CALL apoc.periodic.iterate( 'UNWIND $addresses as item return item',\n",
    "                    'Match (a:Address {address: item}) set a.association = \"%s\" return a', \n",
    "                    {batchSize:1000, parallel:true, iterateList:true, params:{addresses:%s}})\"\"\" % (walletString, list_of_Addresses)\n",
    "    result = conn.query(query,db='neo4j')\n",
    "    print(result)\n",
    "    return walletAddresses, walletString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional remarks and examples\n",
    "#print(len(wallets))\n",
    "#output of 13iQsrwBYdrLpnitG5EV79o3PeHjH8XUBc:  \n",
    "\"\"\"137373\n",
    "Execution time Query: 3572.6374530792236 seconds\n",
    "Execution time inWallet: 158.30259037017822 seconds\n",
    "Execution time IF: 0.022434473037719727 seconds   | Going into statement:  2  times.\"\"\"\n",
    "#1EYya5dfNvuYDwpeboGKBtkXzJcEHMCQXR '1PeSDEMzi7nj1ah4YFcgnRmijWpgQqP3Yp' '1P963yWMBFkUouU2Me7cQ6136orZDD4gTf' '1KFiRjjvE4rtheuEYGo9VeDDBvGgmm7nRg' exchanges: Btc38.com-1CELa15H4DMzHtHnuz7LCpSFgFWf61Ra6A, \n",
    "# QuadrigaCX.com-1LQF9Suqgm4YtxY6kriiE8DJftNTPTqwAm, CoinHako.com- 3PpSAGEGfA9e995bpCkAFdKaw3fMmo8Eyw, MaiCoin.com - 1Lfktsua4x25UcsqDeuXUrXZq3jSoPpJ1b, Hashnest - 1D7JStLYKJ2ma6yfH7a7DXSom5ZPfyfNM3\n",
    "#wallets\n",
    "#no batching: 1EYya5dfNvuYDwpeboGKBtkXzJcEHMCQXR - 7sec, 13iQsrwBYdrLpnitG5EV79o3PeHjH8XUBc - cancelled after 4 hours, \n",
    "#batching with 6: 1EYya5dfNvuYDwpeboGKBtkXzJcEHMCQXR - 1.3sec, 13iQsrwBYdrLpnitG5EV79o3PeHjH8XUBc - cancelled after 6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mihWhereList = \"\"\"MATCH (a:Address)-[:SENDS]->(t:Transaction), (walletMember:Address)-[:SENDS]->(t:Transaction) \n",
    "where a.address in %s\n",
    "RETURN DISTINCT walletMember\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through the addresses and finding all the addresses that are connected to the input address.\n",
    "# Store all responses in a dictionary and instead of looping over every item and adding only new Addresses to the list,\n",
    "# write all records of a response into the dictionary. They addresses are the keys\n",
    "# additionally use a batched version if the amount of retrieved records is greater than 10\n",
    "def iterMultiInputClustering_chunks(address):\n",
    "    chunk_size = 500\n",
    "    # create initial set of addresses\n",
    "    walletAddresses = {address: 1}\n",
    "    response = conn.query(mihTemplate % address, db='neo4j')\n",
    "\n",
    "    # store every found address as key in the dictionary, values do not matter here, so we just pass 1\n",
    "    for record in response:\n",
    "       walletAddresses [record[0]._properties[\"address\"]]= 1 \n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    while i < len(walletAddresses):\n",
    "\n",
    "        # generate a list of the keys to get an index; this is necessary for the batching\n",
    "        list_ofKeys = list(walletAddresses.keys())\n",
    "        \n",
    "        # if there are less than 10 addresses left between i and the maximum; then no batching is possible\n",
    "        if len(walletAddresses) - i <= chunk_size :\n",
    "\n",
    "            response = conn.query(mihTemplate % list_ofKeys[i], db='neo4j')\n",
    "            \n",
    "            # this automatically resolves duplicates. Instead of iterating over every address one by one in the list and comparing them with the existing set, \n",
    "            # this is more faster since the dictionaries are actually hash tables. So it reaches less than logarithmic runtime\n",
    "            for record in response:\n",
    "                walletAddresses [record[0]._properties[\"address\"]]= 1 \n",
    "            i += 1\n",
    "            list_ofKeys = list(walletAddresses.keys())\n",
    "        \n",
    "        \n",
    "       # batching 10 addresses at once to avoid querying every single transaction in the dictionary\n",
    "       # only possible if there are more than 10 addresses left in the dictionary\n",
    "       # question is if we can further improve this... like with 500 and a function in between that creates a string\n",
    "        while chunk_size < len(walletAddresses) - i:\n",
    "            list_ofKeys = list(walletAddresses.keys())\n",
    "            \n",
    "            response = conn.query(mihWhereList % str(list_ofKeys[i:i+chunk_size]), db='neo4j')\n",
    "            #same as above\n",
    "            for record in response:\n",
    "                walletAddresses [record[0]._properties[\"address\"]]= 1\n",
    "            i += chunk_size\n",
    "            list_ofKeys = list(walletAddresses.keys())\n",
    "    \n",
    "    source = string.ascii_letters + string.digits\n",
    "    walletString = ''.join((random.choice(source) for i in range(32)))\n",
    "    # bevor update prüfe ob es in dem wallet nicht bereits associations gibt\n",
    "    # -> Beispiel von neue Adresse die zu Binance dazugehört\n",
    "    # Was passiert mit Wallets die zusammengeführt werden zu einem späteren Zeitpunkt\n",
    "    # -> Übernimm die erste association \n",
    "    # alle Association des Wallets suchen und mit der Blacklist vergleichen; falls es eine Übereinstimmung gibt setze die Ass. der Blacklist\n",
    "    \n",
    "    \n",
    "    print(\"Updating ... \"+ str(address) +\", with size \" + str(len(walletAddresses)) + \": \" + walletString)\n",
    "    list_of_Addresses = str(list(walletAddresses))\n",
    "    \n",
    "    query = \"\"\"CALL apoc.periodic.iterate( 'UNWIND $addresses as item return item',\n",
    "                    'Match (a:Address {address: item}) set a.association = \"%s\" return a', \n",
    "                    {batchSize:1000, parallel:true, iterateList:true, params:{addresses:%s}})\"\"\" % (walletString, list_of_Addresses)\n",
    "    result = conn.query(query,db='neo4j')\n",
    "    print(result)\n",
    "    return walletAddresses, walletString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12sDU3FyYJXc2oRzE6XXuuhVHCBJvaoCC8: There is already an association in the DB\n"
     ]
    }
   ],
   "source": [
    "def clusterAddresses(addressList):\n",
    "    failing_addresses = []\n",
    "    for address in addressList:\n",
    "        response = conn.query(check_association % address,db='neo4j')\n",
    "        if not response:\n",
    "            try:\n",
    "                iterMultiInputClustering_chunks(address)\n",
    "            except TypeError:\n",
    "                print(address + \" could not be clustered due to internal failure!\")\n",
    "                failing_addresses.append(address)\n",
    "                continue\n",
    "        else:\n",
    "            print(address + \": There is already an association in the DB\")\n",
    "    return  failing_addresses\n",
    "#terrorAddressList.remove(\"1QH9hfeSSb2iftcVpgpQp3NsFD174crFoW\") -> 2.1 mio entries\n",
    "#terrorAddressList.remove(\"3PajPWymUexhewHPczmLQ8CMYatKAGNj3y\") -> 34 mio entries\n",
    "#addresses = [\"12sDU3FyYJXc2oRzE6XXuuhVHCBJvaoCC8\"]\n",
    "#failed_addresses = clusterAddresses(addresses)\n",
    "\n",
    "#addresses = [\"1JpSBaUwrZaEgmsYka7mzm9t3Z4syyaw7A\"]\n",
    "#codes = clusterAddresses(addresses)\n",
    "\n",
    "#print(list(codes.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a953444f3f6a7370568067c59d527322362a757e3663a1ed7da44db03711d09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
