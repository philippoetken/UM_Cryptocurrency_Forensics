{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\info\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\info\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from neo4j) (2022.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\info\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\info\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\info\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\info\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\info\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\info\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\info\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response\n",
    "\n",
    "conn = Neo4jConnection(uri=\"neo4j://127.0.0.1:7687\", user=\"team\", pwd=\"F0110wTh€M0n€y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query terror addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below code is returning a list of all the addresses that are marked as terror addresses.\n",
    "#Query takes around 10 min\n",
    "\n",
    "def returnTerrorAddresses():\n",
    "\n",
    "    query_string = '''\n",
    "    MATCH (a:Address {isTerror: True})\n",
    "    Return a.address\n",
    "    '''\n",
    "\n",
    "    response = conn.query(query_string, db='neo4j')\n",
    "    terrorAddresses = [r[0] for r in response]\n",
    "    return terrorAddresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out entire block if old terrorAddressList saved as pickle should be used\n",
    "def createTerrorAddressList():\n",
    "    terrorAddressList = returnTerrorAddresses()\n",
    "\n",
    "    # save terrorAddressList to file\n",
    "\n",
    "    with open('terrorAddressList.pickle', 'wb') as export:\n",
    "        pickle.dump(terrorAddressList, export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use existing blacklist if exists\n",
    "if not os.path.exists('terrorAddressList.pickle'):\n",
    "    createTerrorAddressList()\n",
    "\n",
    "terrorAddressList = pickle.load(open('terrorAddressList.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove unwanted addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # allows blacklist of addresses in json format. json file retrieved with https://github.com/nicotom/walletexplorer_scrapy\n",
    "# \n",
    "# def createBlacklist():\n",
    "#   dirname = os.path.dirname(os.path.realpath('__file__'))\n",
    "#   folder = os.path.join(dirname, 'exchange_addresses\\\\json\\\\')\n",
    "#   \n",
    "#   def flatten(t):\n",
    "#       return [item for sublist in t for item in sublist]\n",
    "#   \n",
    "#   blacklistAddresses = []\n",
    "#   \n",
    "#   # iterate over collection of exchange addresses in csv format to create blacklist\n",
    "#   # attention, lists are not complete yet!\n",
    "#   \n",
    "#   for file in os.listdir(folder):\n",
    "#       df = pd.read_json(os.path.join(folder, file))\n",
    "#       blacklistAddresses.append(df['addresses'].tolist())\n",
    "#       continue\n",
    "#   \n",
    "#   flatten(flatten(blacklistAddresses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows blacklist of addresses in csv format\n",
    "blacklistAddresses = []\n",
    "def createBlacklist():\n",
    "    dirname = os.path.dirname(os.path.realpath('__file__'))\n",
    "    folder = os.path.join(dirname, 'exchange_addresses\\\\csv\\\\')\n",
    "    \n",
    "    def flatten(t):\n",
    "        return [item for sublist in t for item in sublist]\n",
    "      \n",
    "    # iterate over collection of exchange addresses in csv format to create blacklist\n",
    "    # attention, lists are not complete yet!\n",
    "    \n",
    "    for file in os.listdir(folder):\n",
    "        df = pd.read_csv(os.path.join(folder, file), header=0)\n",
    "        blacklistAddresses.append(df['hashAdd'].tolist())\n",
    "        continue\n",
    "    \n",
    "    flatten(blacklistAddresses)\n",
    "    \n",
    "    #export blacklistAddresses to file\n",
    "    \n",
    "    with open('blacklistAddresses.pickle', 'wb') as export:\n",
    "        pickle.dump(blacklistAddresses, export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use existing blacklist if exists\n",
    "if not os.path.exists('blacklistAddresses.pickle'):\n",
    "    createBlacklist()\n",
    "\n",
    "blacklistAddresses = pickle.load(open('blacklistAddresses.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used for removal of exchange addresses\n",
    "interestingAddresses = []\n",
    "def addressCleanUp(addressList, blacklist):\n",
    "    for address in addressList:\n",
    "        if address not in blacklist:\n",
    "            interestingAddresses.append(address)\n",
    "    return interestingAddresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAddressesToClusterList():\n",
    "    addressesToCluster = addressCleanUp(terrorAddressList, blacklistAddresses)\n",
    "\n",
    "    # save addressesToCluster to file\n",
    "\n",
    "    with open('addressesToCluster.pickle', 'wb') as export:\n",
    "        pickle.dump(addressesToCluster, export)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load addressesToCluster if exists\n",
    "if not os.path.exists('addressesToCluster.pickle'):\n",
    "    createAddressesToClusterList()\n",
    "\n",
    "addressesToCluster = pickle.load(open('addressesToCluster.pickle', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster wallets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mihTemplate = '''\n",
    "MATCH (:Address{address:\"%s\"})-[:SENDS]->(t:Transaction),\n",
    "(walletMember:Address)-[:SENDS]->(t:Transaction)\n",
    "//where t.outDegree <= 1\n",
    "RETURN DISTINCT walletMember.address\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiInputClustering(address, walletAddresses):\n",
    "    response = conn.query(mihTemplate % address, db='neo4j')\n",
    "    newAddresses = [r[0] for r in response]\n",
    "    newAddresses = [a for a in newAddresses if a not in walletAddresses]\n",
    "    walletAddresses += newAddresses\n",
    "    for a in newAddresses:\n",
    "        walletAddresses += multiInputClustering(a, walletAddresses)\n",
    "    return list(set(walletAddresses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same logic as Jochen's code; However, extremly large bitcoin wallets get excluded sofar because\n",
    "#they take too long to be clustered. Example address: 13iQsrwBYdrLpnitG5EV79o3PeHjH8XUBc has more than 137k\n",
    "#addresses in the wallet according to walletexplorer.com\n",
    "#What should we do with them? I tried to solve it with multiprocessing but didn't help\n",
    "\n",
    "def iterMultiInputClustering(address, walletIndex):\n",
    "    walletString = \"Terror-wallet ID\"\n",
    "    walletAddresses = []\n",
    "    response = conn.query(mihTemplate % address, db='neo4j')\n",
    "    newAddresses = [r[0] for r in response]\n",
    "    walletAddresses = [newAddresses, walletString +str(walletIndex)]\n",
    "    for walletAddress in walletAddresses[0]:\n",
    "        if(len(walletAddresses[0])) >1000:\n",
    "            return [address , \"Too many results\"];\n",
    "        response = conn.query(mihTemplate % walletAddress, db='neo4j')\n",
    "        newAddresses = [r[0] for r in response]\n",
    "        newAddresses = [a for a in newAddresses if a not in walletAddresses[0]]\n",
    "        walletAddresses[0] += newAddresses\n",
    "    return walletAddresses\n",
    "\n",
    "#walletIndex = 1\n",
    "#wallets = iterMultiInputClustering(\"13iQsrwBYdrLpnitG5EV79o3PeHjH8XUBc\", walletIndex)\n",
    "#1EYya5dfNvuYDwpeboGKBtkXzJcEHMCQXR\n",
    "#wallets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callInputClustering():\n",
    "    index = 0\n",
    "    walletIndex = 1\n",
    "    #[\"1EYya5dfNvuYDwpeboGKBtkXzJcEHMCQXR\", \"13iQsrwBYdrLpnitG5EV79o3PeHjH8XUBc\", \"1MMaU5nTrFdPZotfwdbv1wWnFjLCTFbpPY\", \"17QAWGVpFV4gZ25NQug46e5mBho4uDP6MD\"]\n",
    "    \n",
    "    terrorCluster = []\n",
    "    while index < len(addressesToCluster):\n",
    "        terrorCluster +=iterMultiInputClustering(addressesToCluster[index], walletIndex)\n",
    "        index +=1 \n",
    "        walletIndex +=1\n",
    "    return terrorCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = callInputClustering()\n",
    "# \n",
    "# def flagAdditionalTerrorAdresses(input):\n",
    "#     query = \"\"\"\n",
    "#     MATCH (a:Address {address: \"%s\"})\n",
    "#     set a.isTerrorMultiInput = True,\n",
    "#     a.terrorWallet = \"%s\"\n",
    "#     Return a.address\n",
    "#     \"\"\"\n",
    "#     indexWallets = 0\n",
    "#     while indexWallets < len(input):\n",
    "#         for address in input[indexWallets]:\n",
    "#             walletID = input[indexWallets+1]\n",
    "#             conn.query(query % (address, walletID), db='neo4j')\n",
    "#         indexWallets += 2\n",
    "# # flagAdditionalTerrorAdresses(input)\n",
    "# \n",
    "# "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d06fc9ed4b774328ae1669b976a7de461f6c6282277a8a3bb34b5a87421f7ca"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
